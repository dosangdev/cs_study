# 연속 메모리 할당

- 프로세스를 메모리에 연속적으로 순서대로 할당하는 방식을 말한다.

## 스와핑

### 순서

1. 메모리에 적재된 프로세스 중 실행되지 않는 프로세스( 입출력 장치를 위한 대기, 오랫동안 사용되지 않는 프로세스 등)를 보조기억장치 일부 영역 (스왑 영역)으로 쫓아낸다.
2. 쫓아 낸 프로세스가 남긴 메모리 공간에 다른 프로세스를 적재하여 실행한다. (스와핑 정의)
3. 추방당한 프로세스가 쫓겨나는 것을 스왑 아웃이라 하고
4. 다시 메모리(그 전과 물리적 주소 다를 수 있음)로 복귀하는 것을 스왑 인이라고 한다.

### 효과

- 메모리 스와핑을 이용하면 메모리 크기보다 큰 프로세스들을 동시에 실행할 수 있다.

## 메모리 할당

### 연속 메모리 할당 3가지 방법

- 최초 적합
    - 운영체제가 메모리 내의 빈 공간을 순차적으로 검색하다 최초로 발견한 빈 공간에 프로세스를 배치하는 방식
    - 검색을 최소화할 수 있고, 빠른 할당이 가능하다.

- 최적 적합
    - 운영체제가 빈 공간을 모두 검색한 후, 적재할 수 있는 공간 중 가장 작은 공간을 프로세스에 할당

- 최악 적합
    - 운영체제가 빈 공간을 모두 검색한 후, 적재할 수 있는 공간 중 가장 큰 공간을 프로세스에 할당

## 외부 단편화

- 연속 메모리 할당 방식을 이용하면 발생하는 문제점
- 프로세스들이 계속 실행되고 종료되면서 메모리 사이 사이에 빈 공간이 생기게 되는데, 어느 순간에는 프로세스를 적재할 수 없을 정도로 작아지면서 사용이 불가능해진다.
- 그리고 그런 조그만 빈 공간이 쌓이면서 메모리 낭비로 이어지고 이것을 바로 외부 단편화라고 한다.

### 해결 방법

- 메모리 압축(메모리 조각 모음)
    - 여기저기 흩어져 있는 메모리 빈 공간을 하나로 모으는 방식이다.
    - 단점
        - 시스템은 하던 일을 중지해야 한다.
        - 메모리에 있는 내용을 옮기즌 작업은 많은 오버헤드를 야기한다.
        - 어떤 프로세스를 어떻게 움직여야 하고, 오버헤드를 최소화하며 압축할 수 있는지에 대한 명확한 방법을 결정하기 어렵다.

### 가상 메모리 기법 (페이징 기법)이 해결 방안이다.

# 페이징을 통한 가상 메모리 관리

### 메모리 연속 할당 방식 문제점

1. 외부 단편화
2. 물리 메모리보다 큰 프로세스를 실행할 수 없다.

### 가상 메모리 관리 기법 2가지

- 페이징 기법
    - 현대 대부분의 운영체제가 사용한다.
- 세그멘테이션

## 페이징이란

- 외부 단편화는 각기 다른 크기의 프로세스들을 메모리에 연속적으로 할당했기 때문에 발생하는 문제이다.
- 그렇다면 메모리와 프로세스들을 각기 같은 크기로 자르고, 불연속적으로 할당한다면 외부 단편화는 발생하지 않는 다는 말이다.

**페이징은 메모리의 물리 주소 공간을 프레임 단위로 자르고, 프로세스의 논리 주소 공간을 페이지 단위로 자른 뒤 각 페이지를 프레임에 할당하는 가상 메모리 관리 기법이다.**

### 스와핑

- 페이징 기법에서 프로세스들은 페이징 단위로 스와핑이 가능하다.
- 페이징 시스템에서는 스왑인을 페이지 인, 스왑 아웃을 페이지 아웃이라고 한다.
- 이것을 통해 한 프로세스의 필요하지 않은 페이지들은 보조기억장치로 스왑인을 시켜서, 물리 메모리보다 큰 프로세스를 실행시킬 수 있다.

## 페이지 테이블

- 프로세스를 메모리에 불연속적으로 배치하면, CPU는 한 페이지 실행을 완료한 후 다음에 실행할 명령어 위치를 찾기 어려워진다.
- 이 때 물리 주소인 프레임에 불연속적으로 페이지가 할당되더라도 페이지 번호와 프레임 번호를 짝지어 CPU로 하여금 다음 페이지를 찾을 수 있도록 하는 페이지 테이블이라는 것이 존재한다.
- 이 페이지 테이블은 메모리에 적재되어 있다.
- CPU는 페이지 테이블 베이스 레지스터(PTBR)을 이용해 페이지 테이블이 적재된 메모리의 위치를 알 수 있다.

### 페이지 테이블을 메모리에 두면 생기는 문제점

- CPU의 메모리 접근 시간이 두배가 된다.
- 왜냐하면 페이지 테이블을 찾기 위해 메모리에 접근 1번, 페이지 테이블을 보고 페이지를 찾기 위해 메모리 접근 1번 총 두번이기 때문이다.
- 하지만 CPU 곁에는 TLB라는 페이지 테이블 캐시 메모리가 있다.
    - 주로 최근에 사용된 페이지 위주로 저장한다고 한다.
    - TLB에 참조할 페이지 테이블이 있을 경우 TLB 히트라고 한다.
    - 반대로 없을 경우 TLB 미스라고 한다.

## 페이징에서의 주소 변환

- 하나의 페이지 혹은 프레임은 여러 주소를 포괄하고 있다. (주소와 관계없이 일정한 크기로 잘려서)
- 그렇기에 특정 주소에 접근하려면 두 가지 정보가 필요하다.
    - 어떤 페이지 혹은 프레임에 접근하고 싶은지 (페이지 번호 OR 프레임 번호)
    - 접근하려는 주소가 그 페이지 혹은 프레임으로부터 얼마나 떨어져 있는지 (변위)

### 페이지 번호 → 프레임 번호

- 페이지 번호는 페이지 테이블로 인해 프레임 번호로 변하게 된다.
- 변위 값은 똑같이 유지된다.

### 예제

- 한 페이지/프레임 당 4개의 주소로 구성되어 있다.
- CPU가 5번 페이지의 변위 2라는 주소에 접근하고 싶다.
- 페이지 테이블을 참고하여 해당 프레임 번호로 이동 한다.
- 프레임 번호의 시작지점에서 변위를 더하면 원하는 주소의 값이 나온다.

## 페이지 테이블 엔트리

프레임 번호 외에도 다른 중요한 정보들이 있다.

### 유효 비트

- 현재 페이지가 메모리에 적재되어 있는지 아니면 보조기억장치에 있는지를 알려주는 비트이다.
    - 한마디로 해당 페이지에 접근 가능한지 여부를 알려준다.
- 메모리 적재되어 있다면 1, 보조기억장치에 있다면 0을 표시한다.
- 만일 CPU가 유효비트 0인 페이지로 접근하려고 하면 페이지 폴트라는 예외가 발생한다.
    - CPU가 페이지 폴트를 처리하는 과정은 하드웨어 인터럽트를 처리하는 과정과 유사하다.
        - CPU는 기존 작업 내용을 백업한다.
        - 페이지 폴트 처리 루틴을 실행한다.
        - 페이지 처리 루틴은 원하는 페이지를 메모리로 가져온 뒤 유효 비트를 1로 변경한다.
        - 페이지 폴트 처리 후 CPU는 해당 페이지에 접근 가능하다.

### 보호비트

- 읽기, 쓰기, 실행 여부를 알 수 있게 해주는 비트

| 읽기(r) | 쓰기(w) | 실행(x) |
| --- | --- | --- |
| 1 | 0 | 0 |
| 1 | 1 | 0 |
| 1 | 1 | 1 |

### 참조 비트

- CPU가 이 페이지에 접근한 적이 있는지를 알려주는 비트
    - 적재 이후 CPU가 읽거나 썼다면 1, 아니면 0

### 수정 비트

- 해당 페이지에 데이터를 쓴 적이 있는지 없는지 알려주는 비트
    - 1이면 변경된 적 있음, 0이면 접근을 안했거나, 읽기만 한 경우

### 왜 수정 비트가 필요할까?

- CPU는 메모리를 읽기 뿐만 아니라 쓰기도 한다.
- 메모리에 적재된 페이지A가 적재된 후 CPU가 쓴 적이 없어 데이터가 유지되있다고 가정하자
- 페이지A는 메모리에 적재되기 전 보조기억장치에 있는 데이터와 동일할 것이다.
- 이 때 페이지A가 스왑 아웃되서 보조기억장치로 간다면 같은 데이터이기에 그냥 덮어쓰기만 하면 된다.
- 하지만 페이지A가 메모리에 적재되었을 때 CPU가 쓰기를 하여 데이터가 변경되었다면?
- 변경된 값을 보조기억장치에 기록하는 작업이 필요하기에 이 비트가 있는 것이다.

### 내부 단편화

- 내부 단편화는 페이지를 일정 크기로 자르기 때문에 발생하는 문제이다.
- 프로세스를 일정 크기로 (배수로) 똑같이 자르고 싶어도 조금씩 남는 경우가 무조건 생긴다.
- 그 조금씩 남는 경우가 생겨 메모리 낭비를 발생시키는게 바로 내부 단편화이다.

### 해결 방법

- 페이지 크기를 줄인다.
    - 하지만 너무 작을 경우 페이지 테이블이 너무 커져 공간이 낭비된다.
- 리눅스의 경우 기본 페이지 보다 더 큰 페이지를 만들 수 있게 허락한다.
    - 이것을 휴즈 페이지라고 한다.

## 페이징의 이점 - 쓰기 시 복사

- 프로세스 간에 페이지를 공유할 수 있는 이점

### 프로세스 fork 자식 프로세스 & 부모 프로세스

- 부모 프로세스를 fork 시스템 호출로 통째로 복사하여 자식 프로세스를 만든다.
- 하지만 이 방식은 자식과 부모가 값만 같고, 서로 공유하지 않는 다른 프로세스가 된다.
- 생성 시간이 걸릴 뿐더러, 메모리 공간이 낭비된다.

### 반대로 쓰기 시 복사에서는 자식과 부모가 동일한 프레임을 가리킨다.

- 읽기 작업만 한다면 이렇게 계속 공통된 프레임을 가리키는 것이 가능하다.
- 단지 페이지에 쓰기 작업을 한다면, 그 순간 자식 프로세스의 해당 페이지가 별도의 공간으로 복제가 되면서, 자식 프로세스의 페이지는 다른 프레임을 가리키게 되는 것이다.
- 이렇게 생성 시간을 줄일 수 있고, 메모리 낭비도 막을 수 있다.

## 계층적 페이지

페이지 테이블의 크기는 생각보다 작지 않다.

그래서 페이지 테이블 엔트리를 상시 메모리에 적재해 두는 것은 메모리 낭비이다.

이 낭비를 막는 방식을 바로 계층적 페이지라고 한다. ( 다단계 페이지 테이블)

### 방법

- 하나의 큰 테이블 페이지를 여러 개로 쪼갠다.
- 쪼갠 테이블 페이지들이 어디에 있는지 알려주는 Outer 페이지 테이블을 만든다.
- 그러면 어떤 특정 페이지를 찾으려고 할 때 Outer 페이지 테이블을 참조해서 찾으면 되니, 페이지 테이블들을 항상 메모리에 적재하지 않아도 된다. (보조기억장치에 있어도 무방)
- 단 Outer 페이지 테이블을 항상 메모리에 적재해 두어야 한다.

### 논리 주소가 달라진다

- 페이지 번호와 변위로 이루어졌던 논리 주소가 변한다.
- Outer 페이지 테이블의 페이지 테이블 엔트리 (바깥 페이지) 번호 + 그 Outer 페이지 테이블이 가리키는 페이지 테이블 (안쪽 페이지 테이블)의 번호 + 변위

### 계층이 많다고 반드시 좋은 것은 아니다.

- 페이지 폴트가 발생했을 경우 메모리 참조 횟수가 많아지는 경우에는 좋지 않다.


# 페이지 교체와 프레임 할당

여전히 물리 메모리는 한정되어 있다. 효율적인 메모리 이용이 필요하다. 그 방법으로 3가지를 소개하겠다. 

## 요구 페이징

실행에 요구되는 페이지만 적재하는 기법

### 요구 페이징의 기본적 양상

1. CPU가 특정 페이지에 접근하는 명령어를 실행한다.
2. 해당 페이지가 유효 비트가 1(메모리에 적재)인 경우 CPU는 해당 페이지가 적재된 프레임에 접근한다.
3. 유효 비트가 0(메모리에 없는 경우) 페이지 폴트 발생!
4. 페이지 폴트 처리 루틴을 실행하고 해당 페이지를 메모리에 적재 후 유효 비트를 1로 설정
5. 1번 부터 반복

**순수 요구 페이징**

### 요구 페이징이 안정적으로 실행되는데 필요한 2가지 요소

- 페이지 교체
- 프레임 할당

요구 페이징 기법으로 실행을 하다 보면 메모리는 언젠가 가득 찰 수 밖에 없기 때문에

이 2가지 기법을 사용하여 메모리를 효율적으로 이용해 주어야 한다.

### 페이지 교체 알고리즘

- 페이지 폴트가 가장 적게 발생하는 알고리즘이 바로 좋은 알고리즘이다.
- 그래서 페이지 폴트 횟수를 아는 것이 중요하다.
- 페이지 폴트 횟수를 알려면 페이지 참조열을 보면 알 수 있다.

**예)**

<aside>
💡 2223555337 → 23537

</aside>

- 연속되고 중복된 페이지는 생략했다. 이미 적재된 페이지를 다시 참조하는 것은 페이지 폴트가 발생하지 않기 때문이다.

### 알고리즘 종류 (설명)

1. FIFO 페이지 교체 알고리즘
- 아주 단순하다. 처음 온 애가 자리가 부족하면 나가는 방식

예)

<aside>
💡 2313523423

</aside>

- 4번의 페이지 폴트가 발생한다.

**단점이 너무 명확하다. 초기에 실행되고도 계속 실행되어야 할 프로세스가 있기 때문이다.**

1-1. 2차 기회 페이지 교체 알고리즘

- 참조 비트가 1(CPU가 한 번은 참조 했음)인 경우에 가장 오래있었어도 가장 최근에 메모리에 적재된 프로세스로 간주하여 한 번 더 기회를 준다.
- 참조 비트가 0인 경우 가장 오래 있었으면 쫓겨난다.

1. 최적 페이지 교체 알고리즘
- 앞으로 사용 빈도가 가장 낮은 페이지를 스왑 아웃하는 방식

<aside>
💡 2313523423

</aside>

- 총 2번의 페이지 폴트가 발생한다.

**그런데 구현이 너무 어렵다. 현실적으로 앞으로 사용이 안될 페이지를 예측한다는 것이 불가능하기 때문. 고로 다른 페이지 교체 알고리즘을 이론상 성능을 평가하기 위한 목적으로 사용된다.**

1. LRU 페이지 교체 알고리즘
- Least Recently Used 가장 최근에 사용되지 않은 페이지를 쫓아내는 방식이다.

<aside>
💡 2313523423

</aside>

- 페이지 폴트가 총 3번 발생한다.

**이 밖에도 여러 페이지 교체 알고리즘이 존재한다.** 

## 스래싱과 프레임 할당

사실 페이지 폴트가 자주 발생하는 근본적인 이유는 프레임이 적기 때문이다.

프레임이 적으면 → 페이지 폴트가 자주 발생하게 되고 → CPU는 그만큼 일을 못하게 되어 이용률이 떨어진다.

이처럼 프로세스가 실행되는 시간보다 페이지 교체에 더 많은 시간이 할애되어 성능이 저하되는 것을 **스래싱**이라고 한다.

### 스래싱을 그래프로 표현한 것 (그림 참조)

- CPU 이용률과 멀티프로그래밍의 정도를 세로축과 가로축으로 표현한 그래프
- 멀티프로그래밍이 높아지면 처음에는 CPU 이용률도 비례로 증가하다 어느 선을 기준으로 반비례하게 된다.
- 프로세스가 너무 많아져서 각 프로세스가 할당받는 프레임 수가 줄어들며 페이지 폴트가 지나치게 많이 발생하기 때문이다.

### 프레임 할당 방식 (설명)

**정적 할당 방식**

1. 균등 할당 : 각각의 프로세스에 동일한 프레임을 할당하는 것
2. 비례 할당 : 프로세스의 크기에 비례하여 프레임을 할당하는 것

**동적 할당 방식**

1. 작업 집합 모델 (실행 중인 프로세스가 일정 시간 동안 참조한 페이지의 집합을 작업집합!)
- 참조 지역성의 원리에 의하여 CPU는 주로 비슷한 구역을 집중적으로 참조한다.
- 그래서 특정 시간 동안 몇 개의 페이지를 참조하는지 확인 후 그 만큼의 프레임을 할당하는 방식이다.
1. 페이지 폴트 빈도 (그림 참조)
- 페이지 폴트 비율이 너무 높으면 그 프로세스는 너무 적은 프레임을 가지고 있다.
- 페이지 폴트 비율이 적으면 그 프로세스는 넉넉한 프레임을 가지고 있다.
- 이렇게 두가지의 선을 설정 후 그래프에 가로로 그어 주면 상한선과 하한선이 나오는데 상한선과 하한선 사이가 바로 적당한 프레임 수가 할당된 것이므로 이 범위 안에서만 할당하는 방식이다.