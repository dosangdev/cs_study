# 14장. 가상 메모리

## 14-1. 연속 메모리 할당
#### 연속적 메모리 할당
> 비어 있는 메모리 공간에 프로세스를 연속적으로 할당하는 방식

 1. 최초 적합
    - OS가 메모리 내의 빈 공간을 순서대로 검색하다가, 적재할 수 있는 공간을 발견하면 거기에 프로세스를 배치
    - 검색 최소화, 빠른 할당 가능
 3. 최적 적합
    - OS가 빈 공간을 모두 검색해 본 후, 프로세스가 적재될 수 있는 공간 중 가장 작은 공간에 프로세스를 배치
 5. 최악 적합
    - OS가 빈 공간을 모두 검색해 본 후, 프로세스가 적재될 수 있는 공간 중 가장 큰 공간에 프로세스를 배치

#### 스와핑
> 스와핑 : 현재 실행중이 아닌 프로세스를 임시로 보조기억장치에 쫓아내고, 빈 공간에 다른 프로세스를 적재하는 방식

##### 주요 개념
- 스왑 영역 : 프로세스들이 쫓겨나는 보조기억장치의 영역
- 스왑 아웃 : 메모리에서 스왑 영역으로 쫓겨나는 것
- 스왑 인 : 스왑 영역에서 메모리로 복귀하는 것
<br><br>

##### 특징
- 스와핑을 이용하면 프로세스들이 요구하는 메모리 주소 공간의 크기가 실제 메모리 크기보다 큰 경우에도 프로세스를 동시 실행할 수 있다.
- 연속적 메모리 할당은 외부 단편화라는 문제를 발생시킨다.
  
#### 외부 단편화 (external fragmentation)

![image](https://github.com/Minnie5382/devduck-cs-study/assets/97179789/1c91042b-28fc-4785-b97e-e43a5ff7c20d)

> 외부 단편화 : 프로세스를 할당하기 어려울 정도의 작은 메모리 공간들로 인해 메모리가 낭비되는 현상.

- 외부 단편화의 해결 방안 → 메모리 압축(메모리 조각 모음)
> 메모리 압축 : 흩어져 있는 빈 공간들을 모아서 하나의 큰 빈 공간으로 만드는 기술

- 압축 동안 시스템은 작업을 중지해야 함
- 메모리에 있는 데이터를 옮기는 데 오버 헤드↑
- 압축 방법에 대한 결정 어려움

 ➡️ 페이징 기법!


## 14-2. 페이징을 통한 가상 메모리 관리
#### 페이징이란
> 가상 메모리 : 프로그램의 일부만 메모리에 적재하여, 실제 물리 메모리 크기보다 더 큰 프로세스를 실행할 수 있게 하는 기술.

> 페이징 : 가상 메모리 기법의 일종. 프로세스의 논리 주소 공간을 페이지 단위로 자르고, 메모리 물리 주소 공간은 프레임 단위로 자른 뒤 각 페이지를 프레임에 할당하는 기법

이게 무슨 말이냐 하면,

가상 메모리 기술을 사용하는 OS에서는, 메모리에 프로세스가 온전히 턱 하고 올라가지 않는다.

왜냐하면, 프로세스를 전부 다 턱 하고 올려버리면 1. 외부 단편화 발생 2. 메모리보다 큰 프로세스는 실행할 수 없기 때문에 프로세스를 잘게 잘라서, 메모리에 흩어지게 배치한다.

이렇게 함으로써 1. 외부 단편화 문제를 해결하고, 2. 페이징 스와핑을 통해 메모리보다 큰 프로세스도 실행할 수 있게 된다.

또한 프로세스 간 페이지를 공유할 수도 있게 된다. (copy on write)*

![image](https://github.com/Minnie5382/devduck-cs-study/assets/97179789/709a326c-2e71-4383-99c0-0639a61bef0d)

> 페이지 : 프로세스를 잘게 자른 단위<br>
> 프레임 : 메모리를 잘게 자른 단위<br>
> 페이지 스와핑 : 페이지 단위로 스와핑 하는 것. 실행에 필요없는 페이지는 페이지 아웃, 실행에 필요한 페이지만 페이지 인 한다.


> 페이지 테이블 : 페이지 번호-프레임 번호의 일대일 대응표

##### 페이지 테이블의 관리
- 페이지 테이블 또한 메모리에 적재되어 있다.
- 페이지 테이블 베이스 레지스터 (PTBR) : 프로세스의 페이지 테이블이 적재된 주소 정보가 있는 레지스터
- TLB(페이지 테이블의 캐시) : 페이지 테이블의 일부 내용을 저장(캐싱)하는 곳. (주로 최근에 사용된 페이지 위주로 저장)
    - TLB 히트 : 접근하려는 논리 주소에 대한 페이지 번호 정보가 TLB에 있는 경우. 바로 프레임 주소를 알 수 있다. 
    - TLB 미스 : 없는 경우. 어쩔 수 없이 메모리에 적재된 페이지 테이블에 접근하여 프레임 주소를 알아내야 한다.
      
#### 내부 단편화

<img width="500" alt="image" src="https://github.com/Minnie5382/devduck-cs-study/assets/97179789/24589e0c-8145-47a7-b5b9-4f88472f2f1d">

> 내부 단편화 : 페이징 기법 사용 중, 프레임 크기가 페이지 하나의 크기보다 커서 메모리가 낭비되는 현상

- 대형 페이지(huge page)<br>
    리눅스 등 일부 OS에서는 설정된 페이지 크기보다 예외적으로 크기가 큰 몇몇 페이지가 있을 수 있다. 크기가 매우 큰 프로세스를 위한 것이다.
  
#### 페이징 주소 변환
페이징 기법에서 특정 메모리에 접근하려면 1. 접근하려는 페이지 번호와 2. 해당 페이지 내에서 몇번째 메모리인지(offset) 두 가지 정보가 필요하다.

![image](https://github.com/Minnie5382/devduck-cs-study/assets/97179789/3af9f7e2-ee2e-4fe3-a772-3a3f89ab5c80)

만약 페이지 크기를 4로 하는 OS라고 가정한다면,
1. <페이지 번호: 3, offset: 2> 주소에 접근할래
2. 페이지 테이블에서 페이지 번호: 3에 해당하는 프레임 번호 검색 → 프레임 번호: 4
3. <프레임 번호: 4, offset: 2>
4. 4*4 + 3 = 19번

이런 과정을 통해, 논리 주소 <페이지 번호, offset> → 물리 주소 <프레임 번호, offset>로 변환된다.

#### 페이지 테이블 엔트리
> 페이지 테이블 엔트리 : 페이지 테이블의 각각의 행

##### 페이지 테이블 엔트리에 포함되는 정보들
1. 유효 비트
   - 페이지가 메모리에 적재되어 있는지 여부. 적재되어 있으면 1, 않으면 0.
   - 페이지 폴트 예외 : 유효 비트가 0인 페이지에 접근하려고 시도할 때 발생하는 예외.
2. 보호 비트
   - 읽기 전용인 페이지인지 여부. 읽기 전용이면 1, 아니면 0.
   - 보호 비트가 1인 페이지에 쓰기를 시도하면 OS가 막아줌.
   - rwx 형식으로도 표현함 ex) 110 : 읽기/쓰기 가능, 실행 불가능.
3. 참조 비트
   - 적재 이후 APU가 읽거나 쓴 페이지인지 여부. 읽거나 썼으면 1, 안 썼으면 0.
4. 수정 비트(더티 비트)
   - 변경된 적이 있는 페이지인지 여부. 변경된 적 있으면 1, 없으면 0.
   - 페이지가 스왑 아웃될 때, 수정 비트가 1이면 변경된 값을 보조기억장치에 기록해야 한다.
     

#### 쓰기 시 복사 (copy-on-write)

유닉스 등의 OS에서 fork 시스템 콜을 하면 부모 프로세스가 그대로 다른 메모리가 복사되어 자식 프로세스가 만들어진다고 배웠다.

하지만 자식 프로세스가 부모 프로세스의 모든 페이지를 수정하지 않을 수도 있는데, 부모 프로세스를 통채로 복사하는 것은 시간도 너무 오래 걸리고 메모리 낭비를 야기할 수 있다.

그래서 쓰기 시 복사에서는, fork를 통해 프로세스를 복제해도, 자식 프로세스는 부모 프로세스와 동일한 프레임을 가리키고 있다. 

그 상태로 유지하다가, __첫 write가 발생하면 해당 페이지를 다른 메모리 공간에 진짜로 복사하고 내용을 변경한다.__
<br><br><br>
이렇게 하게 되면 수정되지 않은 페이지는 실제로 복사가 되지 않고, 이런 페이지들은 부모 프로세스와 자식 프로세스가 공유하는 페이지가 된다.

#### 계층적 페이지 (다단계 페이지 테이블)
프로세스 크기가 커지면 페이지 테이블의 크기도 너무 커지고, 그러면 메모리에서 차지하는 크기가 점점 커지게 된다.

그래서 페이지 테이블을 몇 개 단위로 묶어서 쪼개고, 이 페이지 묶음을 가리키는 outer 페이지 테이블을 두는 기법을 적용했다.

이를 **계층적 페이지**라고 한다. 이는 2단계뿐만 아니라 3, 4단계, 그 이상의 계층으로도 구성할 수 있다.

<br><br>
계층적 페이지 기법을 사용하면 원본 페이지 테이블 전체가 반드시 메모리에 올라와있지 않아도 된다.

가장 바깥 쪽의 outer 페이지만 메모리에 올라와있으면, 나머지는 보조기억장치에 저장해놓고 필요 시 outer 테이블을 참조하여 원하는 페이지에 접근할 수 있기 때문이다.

다만 페이지 테이블의 계층이 많을 수록 그만큼 페이지 폴트 발생 시 참조 → 참조 → ... 해야하므로 적절한 계층 깊이를 설정해야 한다. 

##### 계층적 페이지에서 주소 변환

<img width="550" alt="image" src="https://github.com/Minnie5382/devduck-cs-study/assets/97179789/b44395ac-3d29-4db6-8592-b3102a8df034">

계층적 페이지에서는 <outer 페이지 번호, 안쪽 페이지 번호, ..., offset> 구조로 메모리 주소를 표현한다.

그리고 계층적 페이지에서는 아래의 단계로 주소 변환이 이루어진다.
![image](https://github.com/Minnie5382/devduck-cs-study/assets/97179789/b738f835-030a-459e-a873-bb918725f544)

메모리에 전체 테이블이 올라와있지 않는데도 OS는 안쪽 페이지 번호, offset까지 정확하게 알고 있다. 이는 메모리 커널 영역에 메타데이터를 저장하고 있어서 이를 통해 페이지 테이블의 전체 구조를 파악하고 있기 때문이다.

## 14-3. 페이지 교체와 프레임 할당
#### 요구 페이징
> 요구 페이징 : 프로세스 적재 시 필요한 페이지만 메모리에 적재하는 기법
###### + 순수 요구 페이징이란 아무 페이지도 메모리에 적재하지 않고 실행하는 기법

요구 페이징 시스템을 사용하려면 **1. 페이지 교체**에 대한 알고리즘과 **2. 프레임 할당**에 대한 알고리즘이 필요하다.

#### 페이지 교체 알고리즘
> 새로운 페이지를 스왑 인 하기 위해 적재되어있는 페이지 중 하나를 스왑 아웃 해야할 때, 스왑 아웃할 페이지를 선택하는 알고리즘

- 페이지 교체 알고리즘에서 가장 좋은 알고리즘의 기준은 페이지 폴트의 횟수가 적은 알고리즘이다.
- 페이지 폴트가 적게 발생했다는 것은, 스왑 아웃할 페이지를 잘 골랐다는 의미이기 때문이다.
- 페이지 폴트가 발생한 횟수는 **페이지 참조열**을 통해 알 수 있다.

> 페이지 참조열 : 페이지를 참조한 순서 (연속으로 중복된 페이지는 제외)

- 바로 직전에 참조한 페이지를 또 참조하는 것은 페이지 폴트를 절대 일으키지 않기 때문이다.
- 아래와 같은 페이지 참조 순서가 있을 때,
  
  ```
  2 2 2 3 5 5 5 3 3 7
  ```
- 이 경우 페이지 참조열은 다음과 같다
  
  ```
  2 3 5 3 7
  ```

#### 1. FIFO 페이지 교체 알고리즘
> 오래 머무른 페이지부터 나가라

다음과 같은 참조열이 있다고 하자.
````
2 3 1 3 𝟱 𝟮 𝟯 𝟰 2 3
````
페이지 폴트는 `𝟱 𝟮 𝟯 𝟰`에서 발생한다. (4번)

- 아이디어와 구현이 간단하다.
- 좋은 알고리즘이 아니다 = 페이지 폴트 횟수가 많은 편이다.

#### 2. 2차 기회 페이지 교체 알고리즘
> FIFO 알고리즘 + 참조 비트가 1일 경우 한번 더 기회 줄게.

- 기본적으로 FIFO 알고리즘과 같이 가장 오래된 페이지부터 아웃된다.
- 다만, 가장 오래된 페이지의 참조 비트가 1인 경우엔 오래 머무리긴 했지만 CPU가 사용했던 페이지라는 의미이므로, 이 페이지는 삭제하지 않는다.
- 대신에 참조 비트를 0으로 바꾸고 현재 시점으로 새로 적재한다.
- 이를 반복하다가 가장 오래되었으면서 참조 비트가 0인 페이지가 나오면 이 페이지를 아웃시키고 그 자리에 새로운 페이지를 인한다.

#### 3. 최적 페이지 알고리즘 
> 앞으로 참조될 횟수가 가장 적은 페이지를 아웃시키는 알고리즘

```
2 3 1 3 𝟱 2 3 𝟰 2 3
```
페이지 폴트는 `𝟱` `𝟰`에서 발생한다. (2번)

- 말이 안된다. 이상적이지만 현실적이지 않은 알고리즘.
- 페이지 폴트 횟수의 하한선을 설정하는 용도로 사용 (2번)

#### 4. LRU 페이지 교체 알고리즘 (Least Recently Used)
> 지금까지 참조된 횟수가 가장 적은 페이지를 아웃시키는 알고리즘

```
2 3 1 3 𝟱 𝟮 3 𝟰 2 3
```
페이지 폴트는 `𝟱 𝟮` `𝟰`에서 발생한다. (3번)

- '최근에 사용되지 않은 페이지는 앞으로도 사용하지 않을 것이다' 라는 가정으로 만들어진 알고리즘.

#### 프레임 할당
> 프레임 할당 : 각 프로세스에게 사용 가능한 프레임의 개수를 할당하는 것
- 한 프로세스에게 프레임을 필요보다 너무 많이 적게 할당하면 이 프로세스는 일반적으로 페이지 폴트 횟수가 늘어난다.
- 메모리의 크기는 한정되어 있기 때문에, 각 프로세스에게 필요한 최소 프레임 개수를 파악하고 프레임을 적절한 개수로 할당해야 한다.

> 스래싱(thrasing) : 지나치게 빈번한 페이지 폴트의 발생으로 CPU 이용률이 현저히 떨어지는 현상

<img width="450" alt="image" src="https://github.com/Minnie5382/devduck-cs-study/assets/97179789/c97a502b-63ff-48c5-b3c5-03f61b7346a7">

- 위 그래프에서, 멀티 프로그래밍의 정도가 높아질수록 CPU 사용률이 증가하는데, 특정 시점부터는 급격히 낮아진다.
- 메모리에 적재된 프로세스 수가 너무 많아서, 각 프로세스가 이용 가능한 프레임 개수가 너무 적어졌기 때문.
- 스래싱이 발생하지 않도록 프레임을 할당해야 한다.

### 프레임 할당 방식
#### 1. 균등 할당 & 비례 할당
> 균등 할당 : 단순하게 모든 프로세스에 동일한 개수의 프레임을 분배하는 것
>
> 비례 할당 : 프로세스 크기와 비례하여 프레임을 할당하는 것

 - 정적 할당 방식
 - 직관적으로도, 효율적인 알고리즘은 아니다.

#### 2. 작업 집합 모델을 이용한 프레임 할당
> 작업 집합 : 실행 중인 프로세스가 일정 시간동안 참조한 페이지의 집합
>
> 작업 집합 모델을 이용한 프레임 할당 : 작업 집합의 크기만큼 프레임을 할당하는 방식

- 참조 지역성*의 원리에 기반한 알고리즘
- 예를 들어 한 프로세스가 3초 동안 10개의 페이지를 참조했다면, 이 프로세스에겐 10개의 프레임을 할당한다.
###### *참조 지역성 : CPU는 참조했던 곳, 혹은 그곳 주변을 자주 참조하는 경향이 있다. 즉 쓰는 것만 쓴다.

#### 3. 페이지 폴트 빈도를 기반으로 한 프레임 할당
> 페이지 폴트율을 적정선으로 유지하는 프레임 개수를 할당하는 방식.

- 페이지 폴트율이 너무 높으면 프레임이 너무 적은 것이고, 페이지 폴트율이 너무 낮으면 프레임이 너무 많은 것이다.
- 페이지 폴트율의 범위를 정해놓고, 이 범위 안에서만 프레임을 할당한다.
